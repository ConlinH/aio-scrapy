
BOT_NAME = '$project_name'

SPIDER_MODULES = ['$project_name.spiders']
NEWSPIDER_MODULE = '$project_name.spiders'

# SPIDER_MIDDLEWARES = {
#     '$project_name.middlewares.${ProjectName}SpiderMiddleware': 543,
# }

# DOWNLOADER_MIDDLEWARES = {
#     '$project_name.middlewares.${ProjectName}DownloaderMiddleware': 543,
# }

# EXTENSIONS = {
# }

# ITEM_PIPELINES = {
#     '$project_name.pipelines.${ProjectName}Pipeline': 300,
# }

DOWNLOAD_HANDLERS_TYPE = "aiohttp"  # aiohttp httpx pyhttpx requests playwright 不配置则默认为aiohttp
# 自定义发包方式请用scrapy的形式，例如：
# DOWNLOAD_HANDLERS={
#     'http': 'aioscrapy.core.downloader.handlers.aiohttp.AioHttpDownloadHandler',
#     'https': 'aioscrapy.core.downloader.handlers.aiohttp.AioHttpDownloadHandler',
# }

# DOWNLOAD_DELAY = 3
# RANDOMIZE_DOWNLOAD_DELAY = True
CONCURRENT_REQUESTS = 16
CONCURRENT_REQUESTS_PER_DOMAIN = 8

CLOSE_SPIDER_ON_IDLE = False

# LOG_FILE = './log/info.log'
LOG_STDOUT = True
LOG_LEVEL = 'DEBUG'

SCHEDULER_QUEUE_CLASS = 'aioscrapy.queue.redis.SpiderPriorityQueue'
# SCHEDULER_FLUSH_ON_START = False
REDIS_ARGS = {
    'queue': {
        'url': 'redis://:@127.0.0.1:6379/0',
        'max_connections': 2,
        'timeout': None,
        'retry_on_timeout': True,
        'health_check_interval': 30,
    }
}

# 本框架基本实现了scrapy/scrapy-redis的功能 想要配置更多参数，请参考scrapy
